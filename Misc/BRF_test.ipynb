{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "import random\n",
    "%matplotlib inline\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoostedRandomForest :\n",
    "    def __init__(self, T=50, sample_portion=0.6, depth_max=5, criterion='entropy', weight_update=True, boosting=True, debug_msg=False, verbose=False) :\n",
    "        # Inputs \n",
    "        # Max number of trees to be trained\n",
    "        self.T = T\n",
    "        # Portion of sampled subet from training data\n",
    "        self.sample_portion = sample_portion\n",
    "        # Max depth of each tree\n",
    "        self.depth_max = depth_max\n",
    "        # Determine if tree weights are updated during training\n",
    "        self.weight_update = weight_update\n",
    "        # Criterion to train a random tree\n",
    "        self.criterion = criterion\n",
    "        # Determine if boosting is applied during training\n",
    "        self.boosting = boosting\n",
    "        # Determine if debug messages are printed\n",
    "        self.debug_msg = debug_msg\n",
    "        # Enable verbose output of training process\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        # List for training results\n",
    "        # List of trained randome tree classifiers\n",
    "        self.clfs = []\n",
    "        # List of weights to trained trees\n",
    "        self.alphas = []\n",
    "        # features selected for each tree in forest\n",
    "        self.feature_record = pd.DataFrame()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Train boosted random forest\n",
    "    def fit(self, X, y) :\n",
    "        # Number of features\n",
    "        m = X.shape[0]\n",
    "        # Number of examples\n",
    "        N = X.shape[1]\n",
    "        feature_portion = (np.round(np.sqrt(N))/N) *3\n",
    "        \n",
    "        # Initialize training sample weights\n",
    "        W = [1.0/m for i in range(0,m,1)]\n",
    "        W = pd.DataFrame({'Weight':list(W)}, index=X.index)\n",
    "        \n",
    "        # Print debug messages\n",
    "        if self.debug_msg :\n",
    "            print(\"Weight Update:\", self.weight_update)\n",
    "            print(\"Tree Boosting in forming forest:\", self.boosting)\n",
    "            print(\"max depthmax:\", self.depth_max)\n",
    "            print(\"feature_sampling:\", feature_portion)\n",
    "            print(\"training_sample:\", self.sample_portion)\n",
    "            print(\"--------------------------\")\n",
    "            \n",
    "        for i in range(1,self.T+1):\n",
    "            print(\"in loop \", i )\n",
    "            # Prepare training sample subset (bagging)\n",
    "            X_train_sample, X_test_sample, y_train_sample, y_test_sample = train_test_split(X, y, test_size=self.sample_portion)\n",
    "            # Sample feautres to be used for current tree\n",
    "            selected_features =  [random.randint(0,N-1) for j in range(0,int(round(N*feature_portion)))]\n",
    "            # Save selected features for the tree\n",
    "            self.feature_record = self.feature_record.append(pd.DataFrame([selected_features]), ignore_index=True)    \n",
    "            X_train_sample = X_train_sample.iloc[:,selected_features]\n",
    "            X_test_sample = X_test_sample.iloc[:,selected_features]\n",
    "            \n",
    "            # Prepare tree classifier\n",
    "            clf = tree.DecisionTreeClassifier(criterion=self.criterion, max_depth=self.depth_max)\n",
    "            # Weight of training samples\n",
    "            w_ = W.loc[X_train_sample.index,\"Weight\"].tolist()\n",
    "\n",
    "            # Train decision tree\n",
    "            clf.fit(X=X_train_sample, y=y_train_sample,sample_weight=w_)\n",
    "            # Make prediction\n",
    "            pred = clf.predict(X_train.iloc[:,selected_features])\n",
    "\n",
    "            # Calculate weighted error rate of current tree\n",
    "            eps = sum(np.array(W)[(np.ravel(pred) != np.ravel(y))]) / sum(np.array(W))\n",
    "            if self.debug_msg :\n",
    "                print(\"eps: \", eps)\n",
    "            \n",
    "            # Stop training if the error rate is too small\n",
    "            if eps < 1e-20 :\n",
    "                if self.debug_msg :\n",
    "                    print(\"eps == {}. Break\".format(eps))\n",
    "                break\n",
    "                \n",
    "            # Compute weight of decision tree\n",
    "            alpha = (0.5)*np.log( (n_class-1)*(1-eps)/eps )\n",
    "            if self.debug_msg:\n",
    "                print(\"Alpha:\", alpha)\n",
    "\n",
    "            # Update weight of training sample\n",
    "            if alpha > 0 :\n",
    "                # Calculate alphas according to correctness of predictions\n",
    "                exp_alphas = [ np.exp(-alpha) if a==p else np.exp(alpha) for a,p in zip(np.ravel(y), pred) ]\n",
    "                \n",
    "                # Update training sample weights\n",
    "                if self.weight_update==True:\n",
    "                    #with updating\n",
    "                    W = m*np.multiply(W, exp_alphas) / np.sum(np.multiply(W, exp_alphas))\n",
    "                else:\n",
    "                    #weihtout updating\n",
    "                    W = [1.0/m for i in range(0,m,1)]\n",
    "                    W = pd.DataFrame({'Weight':list(W)}, index=X_train.index)\n",
    "\n",
    "                # Save trained tree to list \n",
    "                self.clfs.append(clf)\n",
    "                # Save alpha to list\n",
    "                self.alphas.append(alpha)\n",
    "\n",
    "                if self.boosting==True:\n",
    "                    alphas_ = self.alphas/sum(self.alphas)\n",
    "\n",
    "            else :\n",
    "                # If alpha < 0, reject the tree\n",
    "                if self.debug_msg :\n",
    "                    print(\"Tree {} is rejected.\".format(i))\n",
    "    \n",
    "    \n",
    "    def ensemble_predict(self, X) :\n",
    "        # Normalize alphas\n",
    "        alphas_ = self.alphas / sum(self.alphas)\n",
    "        \n",
    "        # Calculate class probabilities\n",
    "        prob_mat=np.empty([0, X.shape[0]])\n",
    "        for i in range(0,len(self.clfs)):\n",
    "            prob = self.clfs[i].predict_proba(X.iloc[:, list(self.feature_record.iloc[i,:])])[:,1]\n",
    "            prob_mat = np.vstack((prob_mat,prob))\n",
    "        prob_mat = np.transpose(prob_mat)\n",
    "        ensemble_prob = np.matmul(prob_mat,np.array(alphas_))\n",
    "        \n",
    "        # Give predictions\n",
    "        ensemble_pred = ensemble_prob\n",
    "        ensemble_pred[ensemble_prob>=0.5] = 1\n",
    "        ensemble_pred[ensemble_prob<0.5] = 0\n",
    "        \n",
    "        return ensemble_pred\n",
    "    \n",
    "        \n",
    "    # Give predictions with random trees\n",
    "    def RF_predict(self, X) :\n",
    "        # Calculate class probabilities\n",
    "        prob_mat=np.empty([0, X.shape[0]])\n",
    "        for i in range(0,len(self.clfs)):\n",
    "            prob = self.clfs[i].predict_proba(X.iloc[:,list(self.feature_record_.iloc[i,:])])[:,1]\n",
    "            prob_mat = np.vstack ((prob_mat,prob))\n",
    "        prob_mat = np.transpose(prob_mat)\n",
    "        \n",
    "        if len(self.clfs)>1:\n",
    "            ensemble_prob = np.mean(prob_mat,axis=1)\n",
    "        else:\n",
    "            ensemble_prob = prob_mat\n",
    "            \n",
    "        # Give predictions\n",
    "        ensemble_pred= ensemble_prob\n",
    "        ensemble_pred[ensemble_prob>=0.5]=1\n",
    "        ensemble_pred[ensemble_prob<0.5]=0\n",
    "        \n",
    "        return ensemble_pred\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bank = pd.read_csv('bank-full.csv',sep=\";\")\n",
    "bank = pd.read_csv('spambase.csv',sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = bank.shape[1]\n",
    "\n",
    "# Remove unwanted features\n",
    "X = bank.iloc[:,0:48]\n",
    "#X = bank.iloc[:,0:(m-1)]\n",
    "y = bank.iloc[:,(m-1):]\n",
    "n_class = len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_onehot = pd.get_dummies(X_train)\n",
    "X_test_onehot = pd.get_dummies(X_test)\n",
    "#y_train.loc[:,'y'] = y_train.loc[:,'y'].map({'no':0,'yes':1})\n",
    "#y_test.loc[:,'y'] = y_test.loc[:,'y'].map({'no':0,'yes':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "brf = BoostedRandomForest(debug_msg=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight Update: True\n",
      "Tree Boosting in forming forest: True\n",
      "max depthmax: 5\n",
      "feature_sampling: 0.4375\n",
      "training_sample: 0.6\n",
      "--------------------------\n",
      "in loop  1\n",
      "eps:  [0.18405797]\n",
      "Alpha: [0.74454627]\n",
      "in loop  2\n",
      "eps:  [0.27149271]\n",
      "Alpha: [0.49353118]\n",
      "in loop  3\n",
      "eps:  [0.24410706]\n",
      "Alpha: [0.56514643]\n",
      "in loop  4\n",
      "eps:  [0.24784799]\n",
      "Alpha: [0.55506142]\n",
      "in loop  5\n",
      "eps:  [0.34893995]\n",
      "Alpha: [0.31185101]\n",
      "in loop  6\n",
      "eps:  [0.37581283]\n",
      "Alpha: [0.25367953]\n",
      "in loop  7\n",
      "eps:  [0.32448455]\n",
      "Alpha: [0.36661905]\n",
      "in loop  8\n",
      "eps:  [0.34725633]\n",
      "Alpha: [0.31556065]\n",
      "in loop  9\n",
      "eps:  [0.40629792]\n",
      "Alpha: [0.18964548]\n",
      "in loop  10\n",
      "eps:  [0.44537003]\n",
      "Alpha: [0.10969784]\n",
      "in loop  11\n",
      "eps:  [0.41610022]\n",
      "Alpha: [0.16940161]\n",
      "in loop  12\n",
      "eps:  [0.42556041]\n",
      "Alpha: [0.14999401]\n",
      "in loop  13\n",
      "eps:  [0.38696664]\n",
      "Alpha: [0.23004044]\n",
      "in loop  14\n",
      "eps:  [0.40943856]\n",
      "Alpha: [0.18314341]\n",
      "in loop  15\n",
      "eps:  [0.42418443]\n",
      "Alpha: [0.15280955]\n",
      "in loop  16\n",
      "eps:  [0.48147955]\n",
      "Alpha: [0.03705786]\n",
      "in loop  17\n",
      "eps:  [0.40488704]\n",
      "Alpha: [0.19257156]\n",
      "in loop  18\n",
      "eps:  [0.40975887]\n",
      "Alpha: [0.18248114]\n",
      "in loop  19\n",
      "eps:  [0.43775533]\n",
      "Alpha: [0.12513848]\n",
      "in loop  20\n",
      "eps:  [0.49375472]\n",
      "Alpha: [0.01249121]\n",
      "in loop  21\n",
      "eps:  [0.41354509]\n",
      "Alpha: [0.17466462]\n",
      "in loop  22\n",
      "eps:  [0.40714222]\n",
      "Alpha: [0.18789599]\n",
      "in loop  23\n",
      "eps:  [0.39985342]\n",
      "Alpha: [0.20303795]\n",
      "in loop  24\n",
      "eps:  [0.42077338]\n",
      "Alpha: [0.15979969]\n",
      "in loop  25\n",
      "eps:  [0.41058726]\n",
      "Alpha: [0.18076911]\n",
      "in loop  26\n",
      "eps:  [0.47640861]\n",
      "Alpha: [0.04721783]\n",
      "in loop  27\n",
      "eps:  [0.454252]\n",
      "Alpha: [0.09175261]\n",
      "in loop  28\n",
      "eps:  [0.40528865]\n",
      "Alpha: [0.19173832]\n",
      "in loop  29\n",
      "eps:  [0.41081055]\n",
      "Alpha: [0.18030781]\n",
      "in loop  30\n",
      "eps:  [0.44026222]\n",
      "Alpha: [0.12004897]\n",
      "in loop  31\n",
      "eps:  [0.42910261]\n",
      "Alpha: [0.14275671]\n",
      "in loop  32\n",
      "eps:  [0.43364122]\n",
      "Alpha: [0.13350513]\n",
      "in loop  33\n",
      "eps:  [0.33259914]\n",
      "Alpha: [0.34822644]\n",
      "in loop  34\n",
      "eps:  [0.40222675]\n",
      "Alpha: [0.19809776]\n",
      "in loop  35\n",
      "eps:  [0.41054225]\n",
      "Alpha: [0.18086211]\n",
      "in loop  36\n",
      "eps:  [0.46692008]\n",
      "Alpha: [0.06625663]\n",
      "in loop  37\n",
      "eps:  [0.44934207]\n",
      "Alpha: [0.10166469]\n",
      "in loop  38\n",
      "eps:  [0.47495293]\n",
      "Alpha: [0.05013611]\n",
      "in loop  39\n",
      "eps:  [0.45988112]\n",
      "Alpha: [0.08041062]\n",
      "in loop  40\n",
      "eps:  [0.42331722]\n",
      "Alpha: [0.15458527]\n",
      "in loop  41\n",
      "eps:  [0.46634004]\n",
      "Alpha: [0.0674219]\n",
      "in loop  42\n",
      "eps:  [0.40609427]\n",
      "Alpha: [0.19006764]\n",
      "in loop  43\n",
      "eps:  [0.43236891]\n",
      "Alpha: [0.13609627]\n",
      "in loop  44\n",
      "eps:  [0.44301125]\n",
      "Alpha: [0.11447494]\n",
      "in loop  45\n",
      "eps:  [0.40022885]\n",
      "Alpha: [0.20225582]\n",
      "in loop  46\n",
      "eps:  [0.42002753]\n",
      "Alpha: [0.1613302]\n",
      "in loop  47\n",
      "eps:  [0.42747657]\n",
      "Alpha: [0.14607709]\n",
      "in loop  48\n",
      "eps:  [0.45800167]\n",
      "Alpha: [0.08419504]\n",
      "in loop  49\n",
      "eps:  [0.46695591]\n",
      "Alpha: [0.06618464]\n",
      "in loop  50\n",
      "eps:  [0.4449814]\n",
      "Alpha: [0.11048458]\n"
     ]
    }
   ],
   "source": [
    "brf.fit(X_train_onehot, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-277f0143e278>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-38-9ea9bb9dadc9>\u001b[0m in \u001b[0;36mensemble_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mensemble_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;31m# Normalize alphas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0malphas_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malphas\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malphas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# Calculate class probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'list' and 'int'"
     ]
    }
   ],
   "source": [
    "pred = brf.ensemble_predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9391833188531712\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ = brf.RF_predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and unknown targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-a23f41fec31c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/face/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mdiffering_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/face/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 81\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and unknown targets"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, pred_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36750651607298\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
