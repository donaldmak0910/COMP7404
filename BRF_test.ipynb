{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "import random\n",
    "%matplotlib inline\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoostedRandomForest :\n",
    "    def __init__(self, T=50, sample_portion=0.6, depth_max=5, criterion='entropy', weight_update=True, boosting=True, debug_msg=False, verbose=False) :\n",
    "        # Inputs \n",
    "        # Max number of trees to be trained\n",
    "        self.T = T\n",
    "        # Portion of sampled subet from training data\n",
    "        self.sample_portion = sample_portion\n",
    "        # Max depth of each tree\n",
    "        self.depth_max = depth_max\n",
    "        # Determine if tree weights are updated during training\n",
    "        self.weight_update = weight_update\n",
    "        # Criterion to train a random tree\n",
    "        self.criterion = criterion\n",
    "        # Determine if boosting is applied during training\n",
    "        self.boosting = boosting\n",
    "        # Determine if debug messages are printed\n",
    "        self.debug_msg = debug_msg\n",
    "        # Enable verbose output of training process\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        # List for training results\n",
    "        # List of trained randome tree classifiers\n",
    "        self.clfs = []\n",
    "        # List of weights to trained trees\n",
    "        self.alphas = []\n",
    "        # features selected for each tree in forest\n",
    "        self.feature_record = pd.DataFrame()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Train boosted random forest\n",
    "    def fit(self, X, y) :\n",
    "        # Number of features\n",
    "        m = X.shape[0]\n",
    "        # Number of examples\n",
    "        N = X.shape[1]\n",
    "        feature_portion = (np.round(np.sqrt(N))/N) *3\n",
    "        \n",
    "        # Initialize training sample weights\n",
    "        W = [1.0/m for i in range(0,m,1)]\n",
    "        W = pd.DataFrame({'Weight':list(W)}, index=X.index)\n",
    "        \n",
    "        # Print debug messages\n",
    "        if self.debug_msg :\n",
    "            print(\"Weight Update:\", self.weight_update)\n",
    "            print(\"Tree Boosting in forming forest:\", self.boosting)\n",
    "            print(\"max depthmax:\", self.depth_max)\n",
    "            print(\"feature_sampling:\", feature_portion)\n",
    "            print(\"training_sample:\", self.sample_portion)\n",
    "            print(\"--------------------------\")\n",
    "            \n",
    "        for i in range(1,self.T+1):\n",
    "            print(\"in loop \", i )\n",
    "            # Prepare training sample subset (bagging)\n",
    "            X_train_sample, X_test_sample, y_train_sample, y_test_sample = train_test_split(X, y, test_size=self.sample_portion)\n",
    "            # Sample feautres to be used for current tree\n",
    "            selected_features =  [random.randint(0,N-1) for j in range(0,int(round(N*feature_portion)))]\n",
    "            # Save selected features for the tree\n",
    "            self.feature_record = self.feature_record.append(pd.DataFrame([selected_features]), ignore_index=True)    \n",
    "            X_train_sample = X_train_sample.iloc[:,selected_features]\n",
    "            X_test_sample = X_test_sample.iloc[:,selected_features]\n",
    "            \n",
    "            # Prepare tree classifier\n",
    "            clf = tree.DecisionTreeClassifier(criterion=self.criterion, max_depth=self.depth_max)\n",
    "            # Weight of training samples\n",
    "            w_ = W.loc[X_train_sample.index,\"Weight\"].tolist()\n",
    "\n",
    "            # Train decision tree\n",
    "            clf.fit(X=X_train_sample, y=y_train_sample,sample_weight=w_)\n",
    "            # Make prediction\n",
    "            pred = clf.predict(X_train.iloc[:,selected_features])\n",
    "\n",
    "            # Calculate weighted error rate of current tree\n",
    "            eps = sum(np.array(W)[(np.ravel(pred) != np.ravel(y))]) / sum(np.array(W))\n",
    "            if self.debug_msg :\n",
    "                print(\"eps: \", eps)\n",
    "            \n",
    "            # Stop training if the error rate is too small\n",
    "            if eps < 1e-20 :\n",
    "                if self.debug_msg :\n",
    "                    print(\"eps == {}. Break\".format(eps))\n",
    "                break\n",
    "                \n",
    "            # Compute weight of decision tree\n",
    "            alpha = (0.5)*np.log( (n_class-1)*(1-eps)/eps )\n",
    "            if self.debug_msg:\n",
    "                print(\"Alpha:\", alpha)\n",
    "\n",
    "            # Update weight of training sample\n",
    "            if alpha > 0 :\n",
    "                # Calculate alphas according to correctness of predictions\n",
    "                exp_alphas = [ np.exp(-alpha) if a==p else np.exp(alpha) for a,p in zip(np.ravel(y), pred) ]\n",
    "                \n",
    "                # Update training sample weights\n",
    "                if self.weight_update==True:\n",
    "                    #with updating\n",
    "                    W = m*np.multiply(W, exp_alphas) / np.sum(np.multiply(W, exp_alphas))\n",
    "                else:\n",
    "                    #weihtout updating\n",
    "                    W = [1.0/m for i in range(0,m,1)]\n",
    "                    W = pd.DataFrame({'Weight':list(W)}, index=X_train.index)\n",
    "\n",
    "                # Save trained tree to list \n",
    "                self.clfs.append(clf)\n",
    "                # Save alpha to list\n",
    "                self.alphas.append(alpha)\n",
    "\n",
    "                if self.boosting==True:\n",
    "                    alphas_ = self.alphas/sum(self.alphas)\n",
    "\n",
    "            else :\n",
    "                # If alpha < 0, reject the tree\n",
    "                if self.debug_msg :\n",
    "                    print(\"Tree {} is rejected.\".format(i))\n",
    "    \n",
    "    \n",
    "    def ensemble_predict(self, X) :\n",
    "        # Normalize alphas\n",
    "        alphas_ = self.alphas / sum(self.alphas)\n",
    "        \n",
    "        # Calculate class probabilities\n",
    "        prob_mat=np.empty([0, X.shape[0]])\n",
    "        for i in range(0,len(self.clfs)):\n",
    "            prob = self.clfs[i].predict_proba(X.iloc[:, list(self.feature_record.iloc[i,:])])[:,1]\n",
    "            prob_mat = np.vstack((prob_mat,prob))\n",
    "        prob_mat = np.transpose(prob_mat)\n",
    "        ensemble_prob = np.matmul(prob_mat,np.array(alphas_))\n",
    "        \n",
    "        # Give predictions\n",
    "        ensemble_pred = ensemble_prob\n",
    "        ensemble_pred[ensemble_prob>=0.5] = 1\n",
    "        ensemble_pred[ensemble_prob<0.5] = 0\n",
    "        \n",
    "        return ensemble_pred\n",
    "    \n",
    "        \n",
    "    # Give predictions with random trees\n",
    "    def RF_predict(self, X) :\n",
    "        # Calculate class probabilities\n",
    "        prob_mat=np.empty([0, X.shape[0]])\n",
    "        for i in range(0,len(self.clfs)):\n",
    "            prob = self.clfs[i].predict_proba(X.iloc[:,list(self.feature_record_.iloc[i,:])])[:,1]\n",
    "            prob_mat = np.vstack ((prob_mat,prob))\n",
    "        prob_mat = np.transpose(prob_mat)\n",
    "        \n",
    "        if len(self.clfs)>1:\n",
    "            ensemble_prob = np.mean(prob_mat,axis=1)\n",
    "        else:\n",
    "            ensemble_prob = prob_mat\n",
    "            \n",
    "        # Give predictions\n",
    "        ensemble_pred= ensemble_prob\n",
    "        ensemble_pred[ensemble_prob>=0.5]=1\n",
    "        ensemble_pred[ensemble_prob<0.5]=0\n",
    "        \n",
    "        return ensemble_pred\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bank = pd.read_csv('bank-full.csv',sep=\";\")\n",
    "bank = pd.read_csv('spambase.csv',sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = bank.shape[1]\n",
    "\n",
    "# Remove unwanted features\n",
    "X = bank.iloc[:,0:48]\n",
    "#X = bank.iloc[:,0:(m-1)]\n",
    "y = bank.iloc[:,(m-1):]\n",
    "n_class = len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_onehot = pd.get_dummies(X_train)\n",
    "X_test_onehot = pd.get_dummies(X_test)\n",
    "#y_train.loc[:,'y'] = y_train.loc[:,'y'].map({'no':0,'yes':1})\n",
    "#y_test.loc[:,'y'] = y_test.loc[:,'y'].map({'no':0,'yes':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "brf = BoostedRandomForest(debug_msg=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight Update: True\n",
      "Tree Boosting in forming forest: True\n",
      "max depthmax: 5\n",
      "feature_sampling: 0.4375\n",
      "training_sample: 0.6\n",
      "--------------------------\n",
      "in loop  1\n",
      "eps:  [0.16985507]\n",
      "Alpha: [0.79332737]\n",
      "in loop  2\n",
      "eps:  [0.20164464]\n",
      "Alpha: [0.68802345]\n",
      "in loop  3\n",
      "eps:  [0.39779004]\n",
      "Alpha: [0.20734092]\n",
      "in loop  4\n",
      "eps:  [0.31746802]\n",
      "Alpha: [0.38271614]\n",
      "in loop  5\n",
      "eps:  [0.33583793]\n",
      "Alpha: [0.34094875]\n",
      "in loop  6\n",
      "eps:  [0.30510466]\n",
      "Alpha: [0.41155319]\n",
      "in loop  7\n",
      "eps:  [0.37844238]\n",
      "Alpha: [0.24808239]\n",
      "in loop  8\n",
      "eps:  [0.35838571]\n",
      "Alpha: [0.29118877]\n",
      "in loop  9\n",
      "eps:  [0.37402548]\n",
      "Alpha: [0.25749287]\n",
      "in loop  10\n",
      "eps:  [0.3776413]\n",
      "Alpha: [0.24978591]\n",
      "in loop  11\n",
      "eps:  [0.27346912]\n",
      "Alpha: [0.48854615]\n",
      "in loop  12\n",
      "eps:  [0.36935998]\n",
      "Alpha: [0.26748175]\n",
      "in loop  13\n",
      "eps:  [0.43880191]\n",
      "Alpha: [0.12301292]\n",
      "in loop  14\n",
      "eps:  [0.37116538]\n",
      "Alpha: [0.26361027]\n",
      "in loop  15\n",
      "eps:  [0.38312091]\n",
      "Alpha: [0.2381612]\n",
      "in loop  16\n",
      "eps:  [0.42349206]\n",
      "Alpha: [0.15422718]\n",
      "in loop  17\n",
      "eps:  [0.41501036]\n",
      "Alpha: [0.17164532]\n",
      "in loop  18\n",
      "eps:  [0.42265212]\n",
      "Alpha: [0.15594779]\n",
      "in loop  19\n",
      "eps:  [0.41551624]\n",
      "Alpha: [0.17060365]\n",
      "in loop  20\n",
      "eps:  [0.39793796]\n",
      "Alpha: [0.20703218]\n",
      "in loop  21\n",
      "eps:  [0.43805991]\n",
      "Alpha: [0.12451977]\n",
      "in loop  22\n",
      "eps:  [0.4275496]\n",
      "Alpha: [0.1459279]\n",
      "in loop  23\n",
      "eps:  [0.40012866]\n",
      "Alpha: [0.20246453]\n",
      "in loop  24\n",
      "eps:  [0.41033766]\n",
      "Alpha: [0.18128485]\n",
      "in loop  25\n",
      "eps:  [0.4075182]\n",
      "Alpha: [0.18711729]\n",
      "in loop  26\n",
      "eps:  [0.42382524]\n",
      "Alpha: [0.15354491]\n",
      "in loop  27\n",
      "eps:  [0.4153819]\n",
      "Alpha: [0.17088023]\n",
      "in loop  28\n",
      "eps:  [0.43794816]\n",
      "Alpha: [0.12474677]\n",
      "in loop  29\n",
      "eps:  [0.4187051]\n",
      "Alpha: [0.16404568]\n",
      "in loop  30\n",
      "eps:  [0.42535031]\n",
      "Alpha: [0.15042376]\n",
      "in loop  31\n",
      "eps:  [0.43152034]\n",
      "Alpha: [0.13782544]\n",
      "in loop  32\n",
      "eps:  [0.43677186]\n",
      "Alpha: [0.12713689]\n",
      "in loop  33\n",
      "eps:  [0.41590457]\n",
      "Alpha: [0.16980426]\n",
      "in loop  34\n",
      "eps:  [0.43403269]\n",
      "Alpha: [0.13270824]\n",
      "in loop  35\n",
      "eps:  [0.4317359]\n",
      "Alpha: [0.1373861]\n",
      "in loop  36\n",
      "eps:  [0.37710686]\n",
      "Alpha: [0.2509232]\n",
      "in loop  37\n",
      "eps:  [0.41808792]\n",
      "Alpha: [0.16531382]\n",
      "in loop  38\n",
      "eps:  [0.44613635]\n",
      "Alpha: [0.10814697]\n",
      "in loop  39\n",
      "eps:  [0.45295009]\n",
      "Alpha: [0.09437905]\n",
      "in loop  40\n",
      "eps:  [0.49579782]\n",
      "Alpha: [0.00840455]\n",
      "in loop  41\n",
      "eps:  [0.41357851]\n",
      "Alpha: [0.17459571]\n",
      "in loop  42\n",
      "eps:  [0.46004298]\n",
      "Alpha: [0.0800848]\n",
      "in loop  43\n",
      "eps:  [0.45333593]\n",
      "Alpha: [0.09360053]\n",
      "in loop  44\n",
      "eps:  [0.45290944]\n",
      "Alpha: [0.09446108]\n",
      "in loop  45\n",
      "eps:  [0.44564519]\n",
      "Alpha: [0.10914092]\n",
      "in loop  46\n",
      "eps:  [0.43803145]\n",
      "Alpha: [0.12457759]\n",
      "in loop  47\n",
      "eps:  [0.40009687]\n",
      "Alpha: [0.20253075]\n",
      "in loop  48\n",
      "eps:  [0.47982576]\n",
      "Alpha: [0.0403704]\n",
      "in loop  49\n",
      "eps:  [0.42972925]\n",
      "Alpha: [0.14147794]\n",
      "in loop  50\n",
      "eps:  [0.42568113]\n",
      "Alpha: [0.1497471]\n"
     ]
    }
   ],
   "source": [
    "brf.fit(X_train_onehot, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-277f0143e278>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-38-9ea9bb9dadc9>\u001b[0m in \u001b[0;36mensemble_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mensemble_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;31m# Normalize alphas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0malphas_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malphas\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malphas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# Calculate class probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'list' and 'int'"
     ]
    }
   ],
   "source": [
    "pred = brf.ensemble_predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9391833188531712\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ = brf.RF_predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and unknown targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-a23f41fec31c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/face/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mdiffering_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/face/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 81\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and unknown targets"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, pred_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36750651607298\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
