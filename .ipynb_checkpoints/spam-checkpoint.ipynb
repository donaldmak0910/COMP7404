{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "import random\n",
    "%matplotlib inline\n",
    "pd.options.mode.chained_assignment = None\n",
    "#bank = pd.read_csv('bank-full.csv',sep=\";\")\n",
    "bank = pd.read_csv('spambase.csv',sep=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>Spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.00               0.64           0.64           0.0   \n",
       "1            0.21               0.28           0.50           0.0   \n",
       "2            0.06               0.00           0.71           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32            0.00              0.00                0.00   \n",
       "1           0.14            0.28              0.21                0.07   \n",
       "2           1.23            0.19              0.19                0.12   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           0.63            0.00              0.31                0.63   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...   char_freq_;  char_freq_(  \\\n",
       "0             0.00            0.00  ...          0.00        0.000   \n",
       "1             0.00            0.94  ...          0.00        0.132   \n",
       "2             0.64            0.25  ...          0.01        0.143   \n",
       "3             0.31            0.63  ...          0.00        0.137   \n",
       "4             0.31            0.63  ...          0.00        0.135   \n",
       "\n",
       "   char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "0          0.0        0.778        0.000        0.000   \n",
       "1          0.0        0.372        0.180        0.048   \n",
       "2          0.0        0.276        0.184        0.010   \n",
       "3          0.0        0.137        0.000        0.000   \n",
       "4          0.0        0.135        0.000        0.000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       3.756                          61   \n",
       "1                       5.114                         101   \n",
       "2                       9.821                         485   \n",
       "3                       3.537                          40   \n",
       "4                       3.537                          40   \n",
       "\n",
       "   capital_run_length_total  Spam  \n",
       "0                       278     1  \n",
       "1                      1028     1  \n",
       "2                      2259     1  \n",
       "3                       191     1  \n",
       "4                       191     1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bank = bank.sort_values(by=['y'])\n",
    "#no_data_cnt = len(bank[bank['y']=='no'])\n",
    "#print(no_data_cnt)\n",
    "#bank = bank.iloc[:80000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = bank.shape[1]\n",
    "\n",
    "# Remove unwanted features\n",
    "X = bank.iloc[:,0:48]\n",
    "#X = bank.iloc[:,0:(m-1)]\n",
    "y = bank.iloc[:,(m-1):]\n",
    "n_class = len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word_freq_make          float64\n",
       "word_freq_address       float64\n",
       "word_freq_all           float64\n",
       "word_freq_3d            float64\n",
       "word_freq_our           float64\n",
       "word_freq_over          float64\n",
       "word_freq_remove        float64\n",
       "word_freq_internet      float64\n",
       "word_freq_order         float64\n",
       "word_freq_mail          float64\n",
       "word_freq_receive       float64\n",
       "word_freq_will          float64\n",
       "word_freq_people        float64\n",
       "word_freq_report        float64\n",
       "word_freq_addresses     float64\n",
       "word_freq_free          float64\n",
       "word_freq_business      float64\n",
       "word_freq_email         float64\n",
       "word_freq_you           float64\n",
       "word_freq_credit        float64\n",
       "word_freq_your          float64\n",
       "word_freq_font          float64\n",
       "word_freq_000           float64\n",
       "word_freq_money         float64\n",
       "word_freq_hp            float64\n",
       "word_freq_hpl           float64\n",
       "word_freq_george        float64\n",
       "word_freq_650           float64\n",
       "word_freq_lab           float64\n",
       "word_freq_labs          float64\n",
       "word_freq_telnet        float64\n",
       "word_freq_857           float64\n",
       "word_freq_data          float64\n",
       "word_freq_415           float64\n",
       "word_freq_85            float64\n",
       "word_freq_technology    float64\n",
       "word_freq_1999          float64\n",
       "word_freq_parts         float64\n",
       "word_freq_pm            float64\n",
       "word_freq_direct        float64\n",
       "word_freq_cs            float64\n",
       "word_freq_meeting       float64\n",
       "word_freq_original      float64\n",
       "word_freq_project       float64\n",
       "word_freq_re            float64\n",
       "word_freq_edu           float64\n",
       "word_freq_table         float64\n",
       "word_freq_conference    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_onehot = pd.get_dummies(X_train)\n",
    "X_test_onehot = pd.get_dummies(X_test)\n",
    "#y_train.loc[:,'y'] = y_train.loc[:,'y'].map({'no':0,'yes':1})\n",
    "#y_test.loc[:,'y'] = y_test.loc[:,'y'].map({'no':0,'yes':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam    1390\n",
      "dtype: int64 Spam    423\n",
      "dtype: int64\n",
      "Spam    0.402899\n",
      "dtype: float64 Spam    0.367507\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(y_train), np.sum(y_test))\n",
    "print(np.mean(y_train), np.mean(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>word_freq_pm</th>\n",
       "      <th>word_freq_direct</th>\n",
       "      <th>word_freq_cs</th>\n",
       "      <th>word_freq_meeting</th>\n",
       "      <th>word_freq_original</th>\n",
       "      <th>word_freq_project</th>\n",
       "      <th>word_freq_re</th>\n",
       "      <th>word_freq_edu</th>\n",
       "      <th>word_freq_table</th>\n",
       "      <th>word_freq_conference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4183</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2691</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4513</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2587</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.68</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3579</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3030</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3940</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2283</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2052</th>\n",
       "      <td>1.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.11</td>\n",
       "      <td>3.33</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2388</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3102</th>\n",
       "      <td>1.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2670</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4322</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2534</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2919</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3409</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2972</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4564</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.70</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3836</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.52</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2258</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2627</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.86</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3079</th>\n",
       "      <td>0.00</td>\n",
       "      <td>14.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4195</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>1.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.61</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4499</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.27</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4180</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3318</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1898</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1932</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.18</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1827</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2044</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1747</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2109</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.34</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2243</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.79</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3273</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2706</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3450 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "4183            0.00               0.00           0.25          0.00   \n",
       "1949            0.00               0.00           0.00          0.00   \n",
       "836             0.00               0.00           1.11          0.00   \n",
       "312             0.00               0.00           0.16          0.00   \n",
       "2152            0.00               0.00           0.00          0.00   \n",
       "2691            0.00               0.00           0.00          0.00   \n",
       "4513            0.00               0.00           0.00          0.00   \n",
       "1024            0.28               0.14           0.14          0.00   \n",
       "2587            0.00               0.61           0.00          0.00   \n",
       "1213            0.00               0.00           0.58          0.58   \n",
       "3579            0.00               0.00           0.00          0.00   \n",
       "3030            0.00               0.00           0.00          0.00   \n",
       "3940            0.00               0.00           0.00          0.00   \n",
       "2283            0.00               0.00           0.00          0.00   \n",
       "1412            0.00               0.00           1.40          0.00   \n",
       "2052            1.11               0.00           0.00          0.00   \n",
       "2388            0.00               2.12           0.00          0.00   \n",
       "3102            1.07               0.00           1.07          0.00   \n",
       "2670            0.00               0.00           0.42          0.00   \n",
       "1382            0.00               0.00           0.00          0.00   \n",
       "4322            0.00               0.00           0.91          0.00   \n",
       "428             0.00               0.00           3.03          0.00   \n",
       "2534            0.00               0.00           0.00          0.00   \n",
       "2919            0.00               0.00           0.50          0.00   \n",
       "1020            0.05               0.05           0.40          0.00   \n",
       "3409            0.00               0.00           0.00          0.00   \n",
       "2972            0.00               0.00           1.31          0.00   \n",
       "4564            0.00               0.00           0.37          0.00   \n",
       "1362            0.00               0.00           1.92          0.00   \n",
       "1739            0.00               0.00           0.00          0.00   \n",
       "...              ...                ...            ...           ...   \n",
       "3836            0.00               0.00           0.82          0.00   \n",
       "465             0.21               0.10           0.52          0.00   \n",
       "2258            0.76               0.00           0.00          0.00   \n",
       "2627            0.00               0.00           0.00          0.00   \n",
       "650             0.00               0.43           0.00          0.00   \n",
       "3079            0.00              14.28           0.00          0.00   \n",
       "4195            0.00               0.00           1.39          0.00   \n",
       "969             1.23               0.00           0.00          0.00   \n",
       "535             0.00               0.00           0.00          0.00   \n",
       "4499            0.00               0.00           0.00          0.00   \n",
       "744             0.00               0.00           0.67          0.00   \n",
       "4180            0.00               0.00           0.00          0.00   \n",
       "3318            0.00               0.00           0.00          0.00   \n",
       "1898            0.00               2.40           0.00          0.00   \n",
       "662             0.00               0.28           0.84          0.00   \n",
       "1932            0.00               0.00           0.00          0.00   \n",
       "2591            0.00               0.00           0.00          0.00   \n",
       "845             0.59               0.00           0.00          0.00   \n",
       "1569            0.09               0.09           1.14          0.00   \n",
       "1827            0.00               0.00           0.00          0.00   \n",
       "2044            0.00               0.00           0.00          0.00   \n",
       "1747            0.00               0.00           0.00          0.00   \n",
       "2109            0.00               0.00           0.00          0.00   \n",
       "102             0.00               0.00           0.00          0.00   \n",
       "2243            0.00               0.00           3.79          0.00   \n",
       "57              0.00               0.00           1.26          0.00   \n",
       "3273            0.00               0.00           0.00          0.00   \n",
       "2706            0.00               0.00           0.00          0.00   \n",
       "578             0.00               0.00           0.00          0.00   \n",
       "2439            0.00               0.00           0.00          0.00   \n",
       "\n",
       "      word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "4183           0.25            0.00              0.00                0.00   \n",
       "1949           0.00            0.00              0.00                0.00   \n",
       "836            0.00            0.00              1.11                0.00   \n",
       "312            0.16            0.00              0.16                0.00   \n",
       "2152           0.00            0.00              0.00                0.00   \n",
       "2691           1.40            0.00              0.00                0.00   \n",
       "4513           0.00            0.00              0.00                0.00   \n",
       "1024           0.00            0.00              0.14                0.00   \n",
       "2587           1.22            0.00              0.00                0.00   \n",
       "1213           0.00            0.00              0.00                0.29   \n",
       "3579           0.00            0.00              0.00                0.00   \n",
       "3030           0.00            0.00              0.00                0.00   \n",
       "3940           0.00            3.44              0.00                0.00   \n",
       "2283           0.00            0.00              0.00                0.00   \n",
       "1412           0.00            0.00              0.00                0.00   \n",
       "2052           0.00            0.00              0.00                0.00   \n",
       "2388           0.00            0.00              0.00                0.00   \n",
       "3102           1.07            1.07              0.00                0.00   \n",
       "2670           0.42            0.14              0.00                0.00   \n",
       "1382           0.91            0.00              0.00                0.00   \n",
       "4322           0.30            0.00              0.00                0.00   \n",
       "428            0.43            0.00              0.86                0.00   \n",
       "2534           2.25            0.00              0.00                0.00   \n",
       "2919           0.00            0.00              0.00                0.00   \n",
       "1020           0.34            0.00              0.00                0.00   \n",
       "3409           0.00            0.00              0.00                0.00   \n",
       "2972           0.00            0.00              0.00                0.00   \n",
       "4564           0.28            0.28              0.00                0.00   \n",
       "1362           0.00            0.00              0.00                0.00   \n",
       "1739           0.00            0.00              0.00                0.00   \n",
       "...             ...             ...               ...                 ...   \n",
       "3836           0.82            0.00              0.00                0.00   \n",
       "465            1.26            0.10              0.00                0.00   \n",
       "2258           0.00            0.00              0.00                0.00   \n",
       "2627           0.00            0.00              0.00                0.00   \n",
       "650            0.43            0.00              0.86                0.00   \n",
       "3079           0.00            0.00              0.00                0.00   \n",
       "4195           0.00            0.00              0.00                0.00   \n",
       "969            0.00            0.46              0.00                0.15   \n",
       "535            0.00            0.00              0.00                0.00   \n",
       "4499           0.00            0.74              0.00                0.00   \n",
       "744            0.27            0.27              0.13                0.00   \n",
       "4180           0.00            0.00              0.00                0.00   \n",
       "3318           0.00            0.00              0.00                0.00   \n",
       "1898           0.80            0.00              0.00                0.00   \n",
       "662            0.28            0.00              0.14                0.00   \n",
       "1932           0.00            0.57              0.00                0.00   \n",
       "2591           0.00            0.00              0.00                0.00   \n",
       "845            0.00            0.00              1.18                0.59   \n",
       "1569           0.38            0.00              0.00                0.09   \n",
       "1827           1.85            0.00              0.00                0.00   \n",
       "2044           0.67            0.00              0.00                0.00   \n",
       "1747           0.00            0.00              2.30                0.00   \n",
       "2109           0.00            0.00              0.00                0.00   \n",
       "102            0.00            0.00              0.00                0.00   \n",
       "2243           0.00            0.00              0.00                0.00   \n",
       "57             0.00            0.00              0.00                0.00   \n",
       "3273           0.00            0.00              0.00                0.00   \n",
       "2706           0.00            0.00              0.00                0.00   \n",
       "578            0.00            0.00              2.10                0.00   \n",
       "2439           0.00            0.00              0.00                0.00   \n",
       "\n",
       "      word_freq_order  word_freq_mail          ...           word_freq_pm  \\\n",
       "4183             0.00            0.00          ...                   0.00   \n",
       "1949             0.00            0.00          ...                   4.00   \n",
       "836              0.00            0.00          ...                   0.00   \n",
       "312              0.65            0.16          ...                   0.00   \n",
       "2152             0.00            0.00          ...                   0.00   \n",
       "2691             0.00            0.00          ...                   0.00   \n",
       "4513             0.00            0.00          ...                   0.00   \n",
       "1024             0.42            0.00          ...                   0.00   \n",
       "2587             0.00            3.68          ...                   0.00   \n",
       "1213             0.00            0.00          ...                   0.00   \n",
       "3579             0.00            0.00          ...                   0.00   \n",
       "3030             0.00            0.00          ...                   0.00   \n",
       "3940             0.00            0.00          ...                   0.00   \n",
       "2283             0.00            0.00          ...                   0.00   \n",
       "1412             0.00            0.00          ...                   0.00   \n",
       "2052             0.00            0.00          ...                   1.11   \n",
       "2388             0.00            2.12          ...                   0.00   \n",
       "3102             0.00            0.00          ...                   0.00   \n",
       "2670             0.00            0.00          ...                   0.14   \n",
       "1382             0.00            0.45          ...                   0.00   \n",
       "4322             0.00            0.00          ...                   0.00   \n",
       "428              0.00            0.00          ...                   0.00   \n",
       "2534             0.00            0.75          ...                   0.00   \n",
       "2919             0.00            0.00          ...                   0.00   \n",
       "1020             0.57            0.05          ...                   0.00   \n",
       "3409             0.00            0.00          ...                   0.00   \n",
       "2972             0.00            0.00          ...                   0.00   \n",
       "4564             0.09            0.00          ...                   0.00   \n",
       "1362             0.00            0.00          ...                   0.00   \n",
       "1739             0.00            3.70          ...                   0.00   \n",
       "...               ...             ...          ...                    ...   \n",
       "3836             0.00            0.00          ...                   0.00   \n",
       "465              0.42            0.52          ...                   0.00   \n",
       "2258             0.00            0.00          ...                   0.00   \n",
       "2627             0.00            0.00          ...                   0.00   \n",
       "650              1.30            0.86          ...                   0.00   \n",
       "3079             0.00            0.00          ...                   0.00   \n",
       "4195             0.00            0.00          ...                   0.00   \n",
       "969              0.00            0.61          ...                   0.00   \n",
       "535              0.00            0.00          ...                   0.00   \n",
       "4499             0.00            0.00          ...                   0.00   \n",
       "744              0.13            0.27          ...                   0.00   \n",
       "4180             0.00            0.00          ...                   0.00   \n",
       "3318             0.00            0.00          ...                   0.14   \n",
       "1898             0.00            0.00          ...                   0.00   \n",
       "662              0.00            0.42          ...                   0.00   \n",
       "1932             0.00            0.00          ...                   0.00   \n",
       "2591             0.00            0.00          ...                   0.00   \n",
       "845              0.59            1.18          ...                   0.00   \n",
       "1569             0.00            0.19          ...                   0.00   \n",
       "1827             0.00            0.00          ...                   0.00   \n",
       "2044             0.00            0.67          ...                   0.00   \n",
       "1747             0.00            0.00          ...                   0.00   \n",
       "2109             0.00            4.34          ...                   0.00   \n",
       "102              0.00            0.00          ...                   0.00   \n",
       "2243             0.00            0.00          ...                   0.00   \n",
       "57               0.00            0.00          ...                   0.00   \n",
       "3273             0.00            0.00          ...                   0.00   \n",
       "2706             0.00            0.00          ...                   0.00   \n",
       "578              0.00            0.00          ...                   0.00   \n",
       "2439             0.00            0.00          ...                   0.00   \n",
       "\n",
       "      word_freq_direct  word_freq_cs  word_freq_meeting  word_freq_original  \\\n",
       "4183              0.00          0.00               0.00                0.00   \n",
       "1949              0.00          0.00               0.00                0.00   \n",
       "836               0.00          0.00               0.00                0.00   \n",
       "312               0.16          0.00               0.00                0.00   \n",
       "2152              0.00          0.00               0.00                0.00   \n",
       "2691              0.00          0.00               0.00                0.00   \n",
       "4513              0.00          0.00               0.00                0.00   \n",
       "1024              0.00          0.00               0.00                0.00   \n",
       "2587              0.00          0.00               0.00                0.00   \n",
       "1213              0.00          0.00               0.00                0.00   \n",
       "3579              0.00          0.00               0.00                0.00   \n",
       "3030              0.00          0.00               0.00                0.00   \n",
       "3940              0.00          0.00               0.00                0.00   \n",
       "2283              0.24          0.00               0.00                0.24   \n",
       "1412              0.00          0.00               0.00                0.00   \n",
       "2052              1.11          0.00               0.00                1.11   \n",
       "2388              0.00          0.00               0.00                0.00   \n",
       "3102              0.00          0.00               0.00                0.00   \n",
       "2670              0.00          0.00               0.00                0.14   \n",
       "1382              0.00          0.00               0.00                0.00   \n",
       "4322              0.00          0.00               0.00                0.00   \n",
       "428               0.00          0.00               0.00                0.00   \n",
       "2534              0.00          0.00               0.00                0.00   \n",
       "2919              0.00          1.01               0.00                1.01   \n",
       "1020              0.00          0.00               0.11                0.00   \n",
       "3409              0.00          0.00               0.00                0.00   \n",
       "2972              0.00          0.00               0.00                0.00   \n",
       "4564              0.00          0.00               0.00                0.00   \n",
       "1362              0.00          0.00               0.00                0.00   \n",
       "1739              0.00          0.00               0.00                0.00   \n",
       "...                ...           ...                ...                 ...   \n",
       "3836              0.00          0.00               0.00                0.00   \n",
       "465               0.00          0.00               0.00                0.00   \n",
       "2258              0.00          0.00               0.76                0.00   \n",
       "2627              0.00          0.00               0.00                1.35   \n",
       "650               0.00          0.00               0.00                0.00   \n",
       "3079              0.00          0.00               0.00                0.00   \n",
       "4195              0.00          0.00               0.00                0.00   \n",
       "969               0.00          0.00               0.00                0.00   \n",
       "535               0.00          0.00               0.00                0.00   \n",
       "4499              0.00          0.00               0.00                0.00   \n",
       "744               0.00          0.00               0.00                0.00   \n",
       "4180              0.00          0.00               0.00                0.00   \n",
       "3318              0.28          0.00               0.00                0.43   \n",
       "1898              0.00          0.00               1.60                0.00   \n",
       "662               0.14          0.00               0.00                0.00   \n",
       "1932              0.00          0.00               0.00                0.00   \n",
       "2591              0.00          0.00               0.00                0.00   \n",
       "845               0.00          0.00               0.00                0.00   \n",
       "1569              0.00          0.00               0.00                0.38   \n",
       "1827              0.00          0.00               1.85                0.00   \n",
       "2044              0.00          0.00               0.00                0.00   \n",
       "1747              0.00          0.00               0.00                0.00   \n",
       "2109              0.00          0.00               0.00                0.00   \n",
       "102               0.00          0.00               0.00                0.00   \n",
       "2243              0.00          0.00               0.00                0.00   \n",
       "57                0.00          0.00               0.00                0.00   \n",
       "3273              4.16          0.00               0.00                0.00   \n",
       "2706              0.00          0.00               0.00                0.00   \n",
       "578               0.00          0.00               0.00                0.00   \n",
       "2439              0.00          0.00               0.00                0.00   \n",
       "\n",
       "      word_freq_project  word_freq_re  word_freq_edu  word_freq_table  \\\n",
       "4183               0.00          0.76           0.25             0.00   \n",
       "1949               0.00          0.00           0.00             0.00   \n",
       "836                0.00          0.00           0.00             0.00   \n",
       "312                0.00          0.00           0.00             0.00   \n",
       "2152               0.00          0.00           0.00             0.00   \n",
       "2691               0.00          0.00           0.00             0.00   \n",
       "4513               1.66          0.00           5.00             0.00   \n",
       "1024               0.00          0.00           0.00             0.00   \n",
       "2587               0.00          0.00           0.00             0.00   \n",
       "1213               0.00          0.00           0.00             0.00   \n",
       "3579               0.00          2.12           0.00             0.00   \n",
       "3030               0.00          0.00           0.00             0.00   \n",
       "3940               0.00          0.00           0.00             0.00   \n",
       "2283               0.00          0.24           0.00             0.00   \n",
       "1412               0.00          0.00           0.00             0.00   \n",
       "2052               3.33          1.11           0.00             0.00   \n",
       "2388               0.00          0.00           0.00             0.00   \n",
       "3102               0.00          0.00           0.00             0.00   \n",
       "2670               0.00          0.14           0.00             0.00   \n",
       "1382               0.00          1.37           0.00             0.00   \n",
       "4322               0.00          0.30           0.30             0.00   \n",
       "428                0.00          0.00           0.00             0.00   \n",
       "2534               0.00          0.00           0.00             0.00   \n",
       "2919               0.00          0.00           1.01             0.00   \n",
       "1020               0.00          0.05           0.00             0.00   \n",
       "3409               0.00          0.00           0.00             0.00   \n",
       "2972               0.00          0.00           0.00             0.00   \n",
       "4564               0.00          0.56           0.09             0.09   \n",
       "1362               0.00          0.00           0.00             0.00   \n",
       "1739               0.00          0.00           0.00             0.00   \n",
       "...                 ...           ...            ...              ...   \n",
       "3836               0.00          0.82           0.00             0.00   \n",
       "465                0.00          0.00           0.00             0.00   \n",
       "2258               0.00          0.76           0.00             0.00   \n",
       "2627               0.00          0.00           0.00             0.00   \n",
       "650                0.00          0.00           0.00             0.00   \n",
       "3079               0.00          0.00           0.00             0.00   \n",
       "4195               0.00          1.04           0.34             0.00   \n",
       "969                0.00          0.00           0.00             0.00   \n",
       "535                0.00          1.17           0.00             0.00   \n",
       "4499               0.00          0.74           0.00             0.00   \n",
       "744                0.00          0.00           0.00             0.00   \n",
       "4180               0.78          0.78           0.78             0.00   \n",
       "3318               0.00          0.57           0.28             0.00   \n",
       "1898               0.00          0.00           0.80             0.00   \n",
       "662                0.00          0.00           0.00             0.00   \n",
       "1932               0.00          0.57           0.00             0.00   \n",
       "2591               0.00          0.00           0.00             0.00   \n",
       "845                0.00          0.00           0.00             0.00   \n",
       "1569               0.00          0.00           0.00             0.00   \n",
       "1827               0.00          0.00           0.00             0.00   \n",
       "2044               0.00          0.00           0.00             0.00   \n",
       "1747               0.00          0.00           0.00             0.00   \n",
       "2109               0.00          0.00           0.00             0.00   \n",
       "102                0.00          0.00           0.00             0.00   \n",
       "2243               0.00          0.00           0.00             0.00   \n",
       "57                 0.00          0.00           0.00             0.00   \n",
       "3273               0.00          0.00           0.00             0.00   \n",
       "2706               0.00          1.38           0.00             0.00   \n",
       "578                0.00          0.00           0.00             0.00   \n",
       "2439               0.00          0.00           0.00             0.00   \n",
       "\n",
       "      word_freq_conference  \n",
       "4183                  0.00  \n",
       "1949                  0.00  \n",
       "836                   0.00  \n",
       "312                   0.00  \n",
       "2152                  0.00  \n",
       "2691                  0.00  \n",
       "4513                  0.00  \n",
       "1024                  0.00  \n",
       "2587                  0.00  \n",
       "1213                  0.00  \n",
       "3579                  0.00  \n",
       "3030                  0.00  \n",
       "3940                  0.00  \n",
       "2283                  0.00  \n",
       "1412                  0.00  \n",
       "2052                  0.00  \n",
       "2388                  0.00  \n",
       "3102                  0.00  \n",
       "2670                  0.00  \n",
       "1382                  0.00  \n",
       "4322                  0.00  \n",
       "428                   0.00  \n",
       "2534                  0.00  \n",
       "2919                  0.00  \n",
       "1020                  0.00  \n",
       "3409                  0.00  \n",
       "2972                  0.00  \n",
       "4564                  0.00  \n",
       "1362                  0.00  \n",
       "1739                  0.00  \n",
       "...                    ...  \n",
       "3836                  0.00  \n",
       "465                   0.00  \n",
       "2258                  0.00  \n",
       "2627                  0.00  \n",
       "650                   0.00  \n",
       "3079                  0.00  \n",
       "4195                  0.00  \n",
       "969                   0.00  \n",
       "535                   0.00  \n",
       "4499                  0.00  \n",
       "744                   0.00  \n",
       "4180                  0.00  \n",
       "3318                  0.00  \n",
       "1898                  0.00  \n",
       "662                   0.00  \n",
       "1932                  0.00  \n",
       "2591                  0.00  \n",
       "845                   0.00  \n",
       "1569                  0.00  \n",
       "1827                  0.00  \n",
       "2044                  0.00  \n",
       "1747                  0.00  \n",
       "2109                  0.00  \n",
       "102                   0.00  \n",
       "2243                  0.00  \n",
       "57                    0.00  \n",
       "3273                  0.00  \n",
       "2706                  1.38  \n",
       "578                   0.00  \n",
       "2439                  0.00  \n",
       "\n",
       "[3450 rows x 48 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ensemble_predict(clfs,X,y,feature_record_,alphas_):\n",
    "    #print(\"SIZE OF INPUT:\",X.shape)\n",
    "    prob_mat=np.empty([0, X.shape[0]])\n",
    "    for i in range(0,len(clfs)):\n",
    "        prob = clfs[i].predict_proba(X.iloc[:,list(feature_record_.iloc[i,:])])[:,1]\n",
    "        prob_mat = np.vstack ((prob_mat,prob))\n",
    "    prob_mat = np.transpose(prob_mat)\n",
    "    ensemble_prob = np.matmul(prob_mat,np.array(alphas_))\n",
    "    #print(\"prob:\",np.round(ensemble_prob,2))\n",
    "\n",
    "    ensemble_pred= ensemble_prob\n",
    "\n",
    "    ensemble_pred[ensemble_prob>=0.5]=1\n",
    "    \n",
    "    ensemble_pred[ensemble_prob<0.5]=0\n",
    "    #print(ensemble_pred.shape)\n",
    "    #print(y_train.shape)\n",
    "    print(\"Accuracy:\",np.mean(np.array(ensemble_pred==y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word_freq_make          float64\n",
       "word_freq_address       float64\n",
       "word_freq_all           float64\n",
       "word_freq_3d            float64\n",
       "word_freq_our           float64\n",
       "word_freq_over          float64\n",
       "word_freq_remove        float64\n",
       "word_freq_internet      float64\n",
       "word_freq_order         float64\n",
       "word_freq_mail          float64\n",
       "word_freq_receive       float64\n",
       "word_freq_will          float64\n",
       "word_freq_people        float64\n",
       "word_freq_report        float64\n",
       "word_freq_addresses     float64\n",
       "word_freq_free          float64\n",
       "word_freq_business      float64\n",
       "word_freq_email         float64\n",
       "word_freq_you           float64\n",
       "word_freq_credit        float64\n",
       "word_freq_your          float64\n",
       "word_freq_font          float64\n",
       "word_freq_000           float64\n",
       "word_freq_money         float64\n",
       "word_freq_hp            float64\n",
       "word_freq_hpl           float64\n",
       "word_freq_george        float64\n",
       "word_freq_650           float64\n",
       "word_freq_lab           float64\n",
       "word_freq_labs          float64\n",
       "word_freq_telnet        float64\n",
       "word_freq_857           float64\n",
       "word_freq_data          float64\n",
       "word_freq_415           float64\n",
       "word_freq_85            float64\n",
       "word_freq_technology    float64\n",
       "word_freq_1999          float64\n",
       "word_freq_parts         float64\n",
       "word_freq_pm            float64\n",
       "word_freq_direct        float64\n",
       "word_freq_cs            float64\n",
       "word_freq_meeting       float64\n",
       "word_freq_original      float64\n",
       "word_freq_project       float64\n",
       "word_freq_re            float64\n",
       "word_freq_edu           float64\n",
       "word_freq_table         float64\n",
       "word_freq_conference    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_onehot.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight Update: True\n",
      "Tree Boosting in forming forest: True\n",
      "max depthmax: 5\n",
      "feature_sampling: 0.4375\n",
      "training_sample: 0.6\n",
      "--------------------------\n",
      "in loop  1\n",
      "eps:  [0.19275362]\n",
      "Alpha: [0.71610806]\n",
      "Tree saved: 1\n",
      "Accuracy: 0.8192875760208514\n",
      "==============================================\n",
      "in loop  2\n",
      "eps:  [0.22179911]\n",
      "Alpha: [0.62760632]\n",
      "Tree saved: 2\n",
      "Accuracy: 0.893136403127715\n",
      "==============================================\n",
      "in loop  3\n",
      "eps:  [0.19553416]\n",
      "Alpha: [0.70722172]\n",
      "Tree saved: 3\n",
      "Accuracy: 0.8879235447437012\n",
      "==============================================\n",
      "in loop  4\n",
      "eps:  [0.34902613]\n",
      "Alpha: [0.31166135]\n",
      "Tree saved: 4\n",
      "Accuracy: 0.9044309296264118\n",
      "==============================================\n",
      "in loop  5\n",
      "eps:  [0.31622417]\n",
      "Alpha: [0.38558938]\n",
      "Tree saved: 5\n",
      "Accuracy: 0.9035621198957429\n",
      "==============================================\n",
      "in loop  6\n",
      "eps:  [0.32876637]\n",
      "Alpha: [0.35688493]\n",
      "Tree saved: 6\n",
      "Accuracy: 0.9113814074717637\n",
      "==============================================\n",
      "in loop  7\n",
      "eps:  [0.30001343]\n",
      "Alpha: [0.42361696]\n",
      "Tree saved: 7\n",
      "Accuracy: 0.9157254561251086\n",
      "==============================================\n",
      "in loop  8\n",
      "eps:  [0.33160707]\n",
      "Alpha: [0.35046273]\n",
      "Tree saved: 8\n",
      "Accuracy: 0.9252823631624674\n",
      "==============================================\n",
      "in loop  9\n",
      "eps:  [0.41552263]\n",
      "Alpha: [0.17059049]\n",
      "Tree saved: 9\n",
      "Accuracy: 0.9304952215464813\n",
      "==============================================\n",
      "in loop  10\n",
      "eps:  [0.39226936]\n",
      "Alpha: [0.2188915]\n",
      "Tree saved: 10\n",
      "Accuracy: 0.9226759339704604\n",
      "==============================================\n",
      "in loop  11\n",
      "eps:  [0.37209119]\n",
      "Alpha: [0.261628]\n",
      "Tree saved: 11\n",
      "Accuracy: 0.9261511728931364\n",
      "==============================================\n",
      "in loop  12\n",
      "eps:  [0.3574167]\n",
      "Alpha: [0.29329706]\n",
      "Tree saved: 12\n",
      "Accuracy: 0.9331016507384883\n",
      "==============================================\n",
      "in loop  13\n",
      "eps:  [0.43561363]\n",
      "Alpha: [0.1294917]\n",
      "Tree saved: 13\n",
      "Accuracy: 0.9322328410078193\n",
      "==============================================\n",
      "in loop  14\n",
      "eps:  [0.42090079]\n",
      "Alpha: [0.15953833]\n",
      "Tree saved: 14\n",
      "Accuracy: 0.9313640312771503\n",
      "==============================================\n",
      "in loop  15\n",
      "eps:  [0.43322082]\n",
      "Alpha: [0.1343611]\n",
      "Tree saved: 15\n",
      "Accuracy: 0.9331016507384883\n",
      "==============================================\n",
      "in loop  16\n",
      "eps:  [0.37994929]\n",
      "Alpha: [0.24488174]\n",
      "Tree saved: 16\n",
      "Accuracy: 0.9304952215464813\n",
      "==============================================\n",
      "in loop  17\n",
      "eps:  [0.46364089]\n",
      "Alpha: [0.07284681]\n",
      "Tree saved: 17\n",
      "Accuracy: 0.9287576020851434\n",
      "==============================================\n",
      "in loop  18\n",
      "eps:  [0.41377834]\n",
      "Alpha: [0.17418377]\n",
      "Tree saved: 18\n",
      "Accuracy: 0.9304952215464813\n",
      "==============================================\n",
      "in loop  19\n",
      "eps:  [0.38777594]\n",
      "Alpha: [0.22833531]\n",
      "Tree saved: 19\n",
      "Accuracy: 0.9365768896611643\n",
      "==============================================\n",
      "in loop  20\n",
      "eps:  [0.39015348]\n",
      "Alpha: [0.22333355]\n",
      "Tree saved: 20\n",
      "Accuracy: 0.9365768896611643\n",
      "==============================================\n",
      "in loop  21\n",
      "eps:  [0.45212231]\n",
      "Alpha: [0.09604966]\n",
      "Tree saved: 21\n",
      "Accuracy: 0.9374456993918332\n",
      "==============================================\n",
      "in loop  22\n",
      "eps:  [0.41140262]\n",
      "Alpha: [0.17908502]\n",
      "Tree saved: 22\n",
      "Accuracy: 0.9357080799304952\n",
      "==============================================\n",
      "in loop  23\n",
      "eps:  [0.40296594]\n",
      "Alpha: [0.19656106]\n",
      "Tree saved: 23\n",
      "Accuracy: 0.9365768896611643\n",
      "==============================================\n",
      "in loop  24\n",
      "eps:  [0.37672813]\n",
      "Alpha: [0.25172952]\n",
      "Tree saved: 24\n",
      "Accuracy: 0.9357080799304952\n",
      "==============================================\n",
      "in loop  25\n",
      "eps:  [0.44024904]\n",
      "Alpha: [0.1200757]\n",
      "Tree saved: 25\n",
      "Accuracy: 0.9365768896611643\n",
      "==============================================\n",
      "in loop  26\n",
      "eps:  [0.46379498]\n",
      "Alpha: [0.07253699]\n",
      "Tree saved: 26\n",
      "Accuracy: 0.9357080799304952\n",
      "==============================================\n",
      "in loop  27\n",
      "eps:  [0.41614922]\n",
      "Alpha: [0.16930078]\n",
      "Tree saved: 27\n",
      "Accuracy: 0.9365768896611643\n",
      "==============================================\n",
      "in loop  28\n",
      "eps:  [0.4618704]\n",
      "Alpha: [0.07640754]\n",
      "Tree saved: 28\n",
      "Accuracy: 0.9383145091225021\n",
      "==============================================\n",
      "in loop  29\n",
      "eps:  [0.42859905]\n",
      "Alpha: [0.14378465]\n",
      "Tree saved: 29\n",
      "Accuracy: 0.9409209383145091\n",
      "==============================================\n",
      "in loop  30\n",
      "eps:  [0.44784702]\n",
      "Alpha: [0.10468672]\n",
      "Tree saved: 30\n",
      "Accuracy: 0.9391833188531712\n",
      "==============================================\n",
      "in loop  31\n",
      "eps:  [0.42837858]\n",
      "Alpha: [0.14423479]\n",
      "Tree saved: 31\n",
      "Accuracy: 0.9409209383145091\n",
      "==============================================\n",
      "in loop  32\n",
      "eps:  [0.42937664]\n",
      "Alpha: [0.14219745]\n",
      "Tree saved: 32\n",
      "Accuracy: 0.9383145091225021\n",
      "==============================================\n",
      "in loop  33\n",
      "eps:  [0.46442354]\n",
      "Alpha: [0.07127337]\n",
      "Tree saved: 33\n",
      "Accuracy: 0.9374456993918332\n",
      "==============================================\n",
      "in loop  34\n",
      "eps:  [0.47604817]\n",
      "Alpha: [0.04794036]\n",
      "Tree saved: 34\n",
      "Accuracy: 0.9383145091225021\n",
      "==============================================\n",
      "in loop  35\n",
      "eps:  [0.45952183]\n",
      "Alpha: [0.08113391]\n",
      "Tree saved: 35\n",
      "Accuracy: 0.9400521285838401\n",
      "==============================================\n",
      "in loop  36\n",
      "eps:  [0.44445208]\n",
      "Alpha: [0.11155631]\n",
      "Tree saved: 36\n",
      "Accuracy: 0.9391833188531712\n",
      "==============================================\n",
      "in loop  37\n",
      "eps:  [0.42452985]\n",
      "Alpha: [0.15210252]\n",
      "Tree saved: 37\n",
      "Accuracy: 0.9383145091225021\n",
      "==============================================\n",
      "in loop  38\n",
      "eps:  [0.42274691]\n",
      "Alpha: [0.15575356]\n",
      "Tree saved: 38\n",
      "Accuracy: 0.9391833188531712\n",
      "==============================================\n",
      "in loop  39\n",
      "eps:  [0.4121962]\n",
      "Alpha: [0.17744689]\n",
      "Tree saved: 39\n",
      "Accuracy: 0.9409209383145091\n",
      "==============================================\n",
      "in loop  40\n",
      "eps:  [0.45403384]\n",
      "Alpha: [0.09219263]\n",
      "Tree saved: 40\n",
      "Accuracy: 0.9409209383145091\n",
      "==============================================\n",
      "in loop  41\n",
      "eps:  [0.47979772]\n",
      "Alpha: [0.04042656]\n",
      "Tree saved: 41\n",
      "Accuracy: 0.9409209383145091\n",
      "==============================================\n",
      "in loop  42\n",
      "eps:  [0.45002639]\n",
      "Alpha: [0.10028203]\n",
      "Tree saved: 42\n",
      "Accuracy: 0.9400521285838401\n",
      "==============================================\n",
      "in loop  43\n",
      "eps:  [0.44102057]\n",
      "Alpha: [0.11851059]\n",
      "Tree saved: 43\n",
      "Accuracy: 0.9400521285838401\n",
      "==============================================\n",
      "in loop  44\n",
      "eps:  [0.40522331]\n",
      "Alpha: [0.19187386]\n",
      "Tree saved: 44\n",
      "Accuracy: 0.9383145091225021\n",
      "==============================================\n",
      "in loop  45\n",
      "eps:  [0.45806325]\n",
      "Alpha: [0.08407102]\n",
      "Tree saved: 45\n",
      "Accuracy: 0.9383145091225021\n",
      "==============================================\n",
      "in loop  46\n",
      "eps:  [0.47359194]\n",
      "Alpha: [0.05286531]\n",
      "Tree saved: 46\n",
      "Accuracy: 0.9391833188531712\n",
      "==============================================\n",
      "in loop  47\n",
      "eps:  [0.4182835]\n",
      "Alpha: [0.16491189]\n",
      "Tree saved: 47\n",
      "Accuracy: 0.9409209383145091\n",
      "==============================================\n",
      "in loop  48\n",
      "eps:  [0.43924968]\n",
      "Alpha: [0.12210387]\n",
      "Tree saved: 48\n",
      "Accuracy: 0.9400521285838401\n",
      "==============================================\n",
      "in loop  49\n",
      "eps:  [0.3994328]\n",
      "Alpha: [0.20391451]\n",
      "Tree saved: 49\n",
      "Accuracy: 0.9400521285838401\n",
      "==============================================\n",
      "in loop  50\n",
      "eps:  [0.39153377]\n",
      "Alpha: [0.22043482]\n",
      "Tree saved: 50\n",
      "Accuracy: 0.9374456993918332\n",
      "==============================================\n"
     ]
    }
   ],
   "source": [
    "T=50 #Max number of trees\n",
    "#random.seed(3)\n",
    "# If boosting == ture, then update weight\n",
    "\n",
    "#sklearn: may have bo\n",
    "#RF: both false\n",
    "#boosted random without update: boosting true\n",
    "weight_update= True\n",
    "Boosting = True\n",
    "m = X_train_onehot.shape[0]\n",
    "N = X_train_onehot.shape[1]\n",
    "feature_portion = (np.round(np.sqrt(N))/N) *3\n",
    "W = [1.0/m for i in range(0,m,1)]\n",
    "W = pd.DataFrame({'Weight':list(W)},index = X_train_onehot.index)\n",
    "feature_record = pd.DataFrame()\n",
    "sample_portion = 0.6\n",
    "depth_max = 5\n",
    "# List of trees\n",
    "clfs = []\n",
    "# List of weights of trees\n",
    "alphas = []\n",
    "print(\"Weight Update:\", weight_update)\n",
    "print(\"Tree Boosting in forming forest:\", Boosting)\n",
    "print(\"max depthmax:\", depth_max)\n",
    "print(\"feature_sampling:\", feature_portion)\n",
    "print(\"training_sample:\", sample_portion)\n",
    "print(\"--------------------------\")\n",
    "for i in range(1,T+1):\n",
    "    print(\"in loop \", i )\n",
    "    # Prepare training sample subset 2(bagging)\n",
    "    X_train_onehot_sample, X_test_onehot_sample, y_train_sample, y_test_sample = train_test_split(X_train_onehot, y_train, test_size=sample_portion)\n",
    "    selected_features =  [random.randint(0,N-1) for j in range(0,int(round(N*feature_portion)))]\n",
    "    feature_record=feature_record.append(pd.DataFrame([selected_features]), ignore_index=True)    \n",
    "    X_train_onehot_sample = X_train_onehot_sample.iloc[:,selected_features]\n",
    "    X_test_onehot_sample = X_test_onehot_sample.iloc[:,selected_features]\n",
    "    # Prepare tree classifier\n",
    "    clf = tree.DecisionTreeClassifier(criterion='entropy',max_depth=depth_max)\n",
    "    # Weight of current training sample\n",
    "    w_ = W.loc[X_train_onehot_sample.index,\"Weight\"].tolist()\n",
    "    \n",
    "    # Train decision tree\n",
    "    clf.fit(X=X_train_onehot_sample, y=y_train_sample,sample_weight=w_)\n",
    "    # Make prediction\n",
    "    pred = clf.predict(X_train_onehot.iloc[:,selected_features])\n",
    "    \n",
    "    # Calculate weighted error rate of current tree\n",
    "    #print(\"sum(np.array(W)): {}\".format(sum(np.array(W))))\n",
    "    eps = sum(np.array(W)[(np.ravel(pred) != np.ravel(y_train))]) / sum(np.array(W))\n",
    "    print(\"eps: \", eps)\n",
    "    #if ((eps > 0.99) and (eps<=1)) :\\\n",
    "    #    print(\"eps == {}. Break\".format(eps))\n",
    "    #    break\n",
    "    if eps < 1e-20 :\n",
    "        print(\"eps == {}. Break\".format(eps))\n",
    "        break\n",
    "    # Compute weight of decision tree\n",
    "    alpha = (0.5)*np.log( (n_class-1)*(1-eps)/eps )\n",
    "    print(\"Alpha:\", alpha)\n",
    "    #alphas.append(alpha)\n",
    "    \n",
    "    \n",
    "#   print( np.array([ int(y==p) for y,p in zip(np.ravel(y_train), pred) ])[np.where(W>0)]         )\n",
    "#    print(\"if all focused preditcted correct then zero:\",sum( (np.ravel(pred) != np.ravel(y_train))[np.ravel(np.array(W)>0) & np.ravel(~np.isnan(W))]) ,sep=\"\")\n",
    "    \n",
    "    # Update weight of training sample\n",
    "    if alpha > 0 :\n",
    "        alphas.append(alpha)\n",
    "\n",
    "        exp_alphas = [ np.exp(-alpha) if y==p else np.exp(alpha) for y,p in zip(np.ravel(y_train), pred) ]\n",
    "        #A=np.array(exp_alphas)\n",
    "        #print (np.ravel(y_train).shape,np.ravel(pred).shape)\n",
    "        #print(sum(np.array(np.ravel(y_train)!=np.ravel(pred))))\n",
    "        #break\n",
    "\n",
    "        if weight_update==True:\n",
    "            #with updating\n",
    "            W = m*np.multiply(W, exp_alphas) / np.sum(np.multiply(W, exp_alphas))\n",
    "        else:\n",
    "            #weihtout updating\n",
    "            W = [1.0/m for i in range(0,m,1)]\n",
    "            W = pd.DataFrame({'Weight':list(W)},index = X_train_onehot.index)\n",
    "\n",
    "        \n",
    "        # Save trained tree to list \n",
    "        clfs.append(clf)\n",
    "        print(\"Tree saved:\",len(clfs))\n",
    "        if Boosting==True:\n",
    "            alphas_ = alphas/sum(alphas)\n",
    "            ensemble_predict(clfs,X_test_onehot,y_test,feature_record,alphas_)\n",
    "        else:\n",
    "            RF_predict(clfs,X_test_onehot,y_test,feature_record)\n",
    "        print(\"==============================================\")\n",
    "    # If alpha < 0, reject the tree\n",
    "        #print('in if then loop')\n",
    "    else :\n",
    "        print(\"Tree {} is rejected.\".format(i))\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "    #X.iloc[X_train.index,:]\n",
    "    #print('The accuracy of Tree ',str(i), ' is ',round(clf.score(X=X_test_onehot_sample, y=y_test_sample),5),sep='')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def RF_predict(clfs,X,y,feature_record_):\n",
    "    #print(\"SIZE OF INPUT:\",X.shape)\n",
    "    prob_mat=np.empty([0, X.shape[0]])\n",
    "    for i in range(0,len(clfs)):\n",
    "        prob = clfs[i].predict_proba(X.iloc[:,list(feature_record_.iloc[i,:])])[:,1]\n",
    "        prob_mat = np.vstack ((prob_mat,prob))\n",
    "    prob_mat = np.transpose(prob_mat)\n",
    "    if len(clfs)>1:\n",
    "        ensemble_prob = np.mean(prob_mat,axis=1)\n",
    "    else:\n",
    "        ensemble_prob = prob_mat\n",
    "    #print(\"prob:\",np.round(ensemble_prob,2))\n",
    "    ensemble_pred= ensemble_prob\n",
    "\n",
    "    ensemble_pred[ensemble_prob>=0.5]=1\n",
    "    \n",
    "    ensemble_pred[ensemble_prob<0.5]=0\n",
    "    #print(ensemble_pred.shape)\n",
    "    #print(y_train.shape)\n",
    "    print(\"Accuracy:\",np.mean(np.array(np.ravel(ensemble_pred)==np.ravel(y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9261511728931364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8731537793223284"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas /= sum(alphas)\n",
    "ensemble_predict(clfs,X_test_onehot,y_test,feature_record,alphas)\n",
    "clfs[0].score(X_test_onehot.iloc[:,list(feature_record.iloc[0,:])],y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.export_graphviz(clfs[0],out_file='tree0.dot') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5\n",
      "(3450, 48)\n",
      "[1.   0.74 0.83 1.   0.74]\n",
      "class: [0 1]\n",
      "0.5684057971014492\n",
      "      Spam\n",
      "4183     0\n",
      "1949     0\n",
      "836      1\n",
      "312      1\n",
      "2152     0\n"
     ]
    }
   ],
   "source": [
    "print(len(alphas),len(clfs))\n",
    "#print(alphas)\n",
    "print(X_train_onehot.shape)\n",
    "i=3\n",
    "print(np.round(clfs[i].predict_proba(X_train_onehot.iloc[:,list(feature_record.iloc[i,:])]),2)[0:5,1])\n",
    "print(\"class:\",clfs[i].classes_)\n",
    "print(clfs[i].score(X_train_onehot.iloc[:,list(feature_record.iloc[i,:])],y_train))\n",
    "np.array(clfs[i].predict(X_train_onehot.iloc[:,list(feature_record.iloc[i,:])]))[0:5]\n",
    "print(y_train[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14339885])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.empty([0, 5])\n",
    "b=[2,3,4,5,6]\n",
    "c=np.vstack((a,b))\n",
    "c=np.vstack((c,b))\n",
    "np.transpose(c)\n",
    "np.array(alphas)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1423.0"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas /= sum(alphas)\n",
    "\n",
    "\n",
    "ensemble_prob = np.zeros(len(X_train_onehot))\n",
    "for i,clf in enumerate(clfs) :\n",
    "    prob = clf.predict_proba(X_train_onehot.iloc[:,list(feature_record.iloc[i,:])])\n",
    "    ensemble_prob += prob[:,1]*alphas[i]\n",
    "    #print(ensemble_prob)\n",
    "\n",
    "#ensemble_prob /= len(clfs)\n",
    "#ensemble_pred = ensemble_prob\n",
    "#ensemble_pred[ensemble_pred>=0.5]=1\n",
    "#ensemble_pred[ensemble_pred<0.5]=0\n",
    "#print(sum(ensemble_pred))\n",
    "#print(ensemble_prob)\n",
    "#ensemble_pred = [ int(pb>0.5) for pb in ensemble_prob ]\n",
    "#print(len(ensemble_pred))\n",
    "ensemble_pred= ensemble_prob\n",
    "ensemble_pred[ensemble_prob>=0.5]=1\n",
    "ensemble_pred[ensemble_prob<0.5]=0\n",
    "sum(ensemble_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_prob>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47159420289855075"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((np.array(y_train)==np.array(ensemble_pred))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas /= sum(alphas)\n",
    "\n",
    "\n",
    "ensemble_prob = np.zeros(len(X_test_onehot))\n",
    "for i,clf in enumerate(clfs) :\n",
    "    prob = clf.predict_proba(X_test_onehot.iloc[:,list(feature_record.iloc[i,:])])\n",
    "    ensemble_prob += prob[:,1]*alphas[i]\n",
    "    #print(ensemble_prob)\n",
    "\n",
    "#ensemble_prob /= len(clfs)\n",
    "#ensemble_pred = ensemble_prob\n",
    "#ensemble_pred[ensemble_pred>=0.5]=1\n",
    "#ensemble_pred[ensemble_pred<0.5]=0\n",
    "#print(sum(ensemble_pred))\n",
    "#print(ensemble_prob)\n",
    "#ensemble_pred = [ int(pb>0.5) for pb in ensemble_prob ]\n",
    "#print(len(ensemble_pred))\n",
    "ensemble_pred= ensemble_prob\n",
    "ensemble_pred[ensemble_prob>=0.5]=1\n",
    "ensemble_pred[ensemble_prob<0.5]=0\n",
    "sum(ensemble_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8841015659559409"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1=((np.ravel(y_test)==np.ravel(ensemble_pred)))\n",
    "np.mean(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y    0.884102\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - np.mean(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8841015659559409\n"
     ]
    }
   ],
   "source": [
    "pred = np.array(ensemble_pred)\n",
    "corr = [ int(y==p) for y,p in zip(pred, np.array(y_test)) ]\n",
    "print( np.mean(corr) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-e8380b358e22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimportances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimportance_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Importance'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimportances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Feature'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_onehot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mimportance_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Importance'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimportance_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'barh'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Feature'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'orange'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/face/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    346\u001b[0m                                  dtype=dtype, copy=copy)\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/face/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_init_dict\u001b[0;34m(self, data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_arrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/face/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_arrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[1;32m   7354\u001b[0m     \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7356\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7358\u001b[0m     \u001b[0;31m# don't force copy because getting jammed in an ndarray anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/face/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   7400\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7401\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7402\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'arrays must all be same length'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7404\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "importances = clf.feature_importances_ \n",
    "importance_frame = pd.DataFrame({'Importance': list(importances), 'Feature': list(X_train_onehot.columns)})\n",
    "importance_frame.sort_values(by = 'Importance', inplace = True)\n",
    "importance_frame.plot(kind = 'barh', x = 'Feature', figsize = (16,100), color = 'orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Random Forest Classifier on testing set: 0.9339704604691572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ginly\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5337277070292067"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=5,criterion='entropy')\n",
    "rfc.fit(X_train_onehot, y_train)\n",
    "print('The accuracy of Random Forest Classifier on testing set:', rfc.score(X_test_onehot, y_test))\n",
    "np.mean(np.array(rfc.predict(X_test_onehot))==np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = np.array(rfc.predict(X_test_onehot))\n",
    "corr = [ int(y==p) for y,p in zip(pred, np.array(y_test)) ]\n",
    "print( np.mean(corr) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import DMatrix\n",
    "xgbc = XGBClassifier()\n",
    "xgbc.fit(X_train_onehot, y_train)\n",
    "print('The accuracy of eXtreme Gradient Boosting Classifier on testing set:', xgbc.score(X_test_onehot, y_test))\n",
    "\n",
    "xgdmat = DMatrix(X_train_onehot, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "cv_params = {'max_depth': [3,5,7], 'min_child_weight': [1,3,5]}\n",
    "ind_params = {'learning_rate': 0.1, 'n_estimators': 1000, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "             'objective': 'binary:logistic'}\n",
    "optimized_GBM = GridSearchCV(xgb.XGBClassifier(**ind_params), \n",
    "                            cv_params, \n",
    "                             scoring = 'accuracy', cv = 5, n_jobs = -1) \n",
    "# Optimize for accuracy since that is the metric used in the Adult Data Set notation\n",
    "\n",
    "optimized_GBM.fit(X_train_onehot, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimized_GBM.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimized_GBM2 = GridSearchCV(cv=5, error_score='raise',\n",
    "       estimator=XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
    "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
    "       min_child_weight=3, missing=None, n_estimators=1000, nthread=-1,\n",
    "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
    "       scale_pos_weight=1, seed=0, silent=True, subsample=1),\n",
    "       fit_params={}, iid=True, n_jobs=-1,\n",
    "       param_grid={'subsample': [0.7, 0.8, 0.9], 'learning_rate': [0.1, 0.01]},\n",
    "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)\n",
    "\n",
    "optimized_GBM2.fit(X_train_onehot, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimized_GBM2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "our_params = {'eta': 0.1, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "             'objective': 'binary:logistic', 'max_depth':3, 'min_child_weight':3} \n",
    "# Grid Search CV optimized settings\n",
    "\n",
    "cv_xgb = xgb.cv(params = our_params, dtrain = xgdmat, num_boost_round = 3000, nfold = 5,\n",
    "                metrics = ['error'], # Make sure you enter metrics inside a list or you may encounter issues!\n",
    "                early_stopping_rounds = 100) # Look for early stopping that minimizes error\n",
    "\n",
    "cv_xgb.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from xgboost import plot_tree\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(font_scale = 1.5)\n",
    "\n",
    "plot_tree(xgbc,rankdir='LR')\n",
    "fig = pyplot.gcf()\n",
    "fig.set_size_inches(150, 100)\n",
    "#fig.savefig('tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "plot_importance(xgbc)\n",
    "fig = pyplot.gcf()\n",
    "fig.set_size_inches(150, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importances = xgbc.feature_importances_\n",
    "importance_frame = pd.DataFrame({'Importance': list(importances), 'Feature': list(X_train_onehot.columns)})\n",
    "importance_frame.sort_values(by = 'Importance', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importance_frame.plot(kind = 'barh', x = 'Feature', figsize = (16,100), color = 'orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig.savefig(\"importance.png\", format=\"PNG\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
